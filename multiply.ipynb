{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dear ML Model, Please Multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how ML models can learn to approximately multiply two numbers, even when the data is noisy.\n",
    "\n",
    "### Basics\n",
    "\n",
    "A typical ML task is to estimate a function $f$ \n",
    "$$\n",
    "    y = f(x_1, x_2, \\dots) + \\varepsilon\n",
    "$$\n",
    "as good as possible by $\\hat f$ from data. Afterward, we can use $\\hat f$ to \n",
    "\n",
    "- gain insights on the relationship between $x_i$ and $y$ and\n",
    "- to make predictions based on $x_i$.\n",
    "\n",
    "The specific steps to find $\\hat f$ depend on the assumed structural form of $f$ and the optimization algorithm used to determine $\\hat f$. \n",
    "\n",
    "### Some examples\n",
    "\n",
    "- **Linear regression**: $f$ is assumed to be linear in its parameters and $\\hat f$ is found by least-squares.\n",
    "- **Generalized linear model**: $g(f)$ is linear and $\\hat f$ is found by iteratively reweighted least-squares.\n",
    "- **Neural net**: $f$ is a composition of linear and non-linear functions, found by auto-differentiation-based gradient descent.\n",
    "- **Decision tree**: $f$ is a binary decision tree, i.e. a collection of yes/no questions calculated by recursion.\n",
    "- **Random forest**: $f$ is the average of randomized decision trees.\n",
    "- **Gradient boosting**: $f$ is the average of decision trees, calculated sequentially. Each tree tries to fix the mistakes of the previous ones.\n",
    "\n",
    "### Outlook\n",
    "\n",
    "In this notebook, we will use neural nets and gradient boosting to learn noisy multiplication of two numbers $x_1$ and $x_2$, i.e.\n",
    "$$\n",
    "    y = f(x_1, x_2) + \\varepsilon = x_1 \\cdot x_2 + \\varepsilon, \n",
    "$$\n",
    "with $\\varepsilon\\sim N(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate noisy data\n",
    "\n",
    "Let's generate one million independent observations of above random process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.427959</td>\n",
       "      <td>-0.909703</td>\n",
       "      <td>2.914672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.521623</td>\n",
       "      <td>-3.973049</td>\n",
       "      <td>-9.736590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.307314</td>\n",
       "      <td>-1.002808</td>\n",
       "      <td>-1.534397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.998346</td>\n",
       "      <td>-0.479178</td>\n",
       "      <td>3.621836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.852353</td>\n",
       "      <td>-1.723083</td>\n",
       "      <td>10.453152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2          y\n",
       "0 -1.427959 -0.909703   2.914672\n",
       "1  2.521623 -3.973049  -9.736590\n",
       "2  1.307314 -1.002808  -1.534397\n",
       "3 -6.998346 -0.479178   3.621836\n",
       "4 -5.852353 -1.723083  10.453152"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gernerate n observations\n",
    "np.random.seed(1901)\n",
    "n = 1_000_000 # 10_000_000\n",
    "df = pd.DataFrame(np.random.uniform(-10, 10, size=(n, 2)), columns=['x1', 'x2'])\n",
    "df['y'] = df.x1 * df.x2 + np.random.normal(scale=1, size=(n, ))\n",
    "df.hist(bins=100, layout=(1, 3), figsize=(15, 4))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    df.drop('y', axis=1), \n",
    "    df.y, \n",
    "    train_size=0.9, \n",
    "    random_state=525\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net\n",
    "\n",
    "Can a neural net predict the result of the (noisy) multiplication if it fed the two inputs?\n",
    "\n",
    "We start with the most simple neural net (no hidden layers) and then, step by step, add more neurons and/or more hidden layers. \n",
    "To do so, we rely on Google's [Keras/Tensorflow](https://www.tensorflow.org/guide/keras/sequential_model?hl=en).\n",
    "\n",
    "It is up to you, dear user, to select the specific architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Plot history (dropping the first m burn-in epochs)\n",
    "def plot_history(h, drop_m=0):\n",
    "    h = pd.DataFrame(h.history.history)\n",
    "    h['epoch'] = np.arange(len(h.index)) + 1\n",
    "    h = h.iloc[drop_m:]\n",
    "    plt.plot(h.epoch, h.loss, label='Training')\n",
    "    plt.plot(h.epoch, h.val_loss, label='Validation')\n",
    "    plt.legend()\n",
    "    \n",
    "# Callbacks to stop if validation performance stops to improve and to lower the learning-rate if appropriate.\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=10, mode='min')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.2)\n",
    "cb = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                60        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural net structure (play with architecture)\n",
    "def fresh_neural_net():\n",
    "    m = keras.Sequential()\n",
    "    m.add(Dense(20, activation='tanh', input_shape=(2, )))\n",
    "    m.add(Dense(1, activation='linear'))\n",
    "    m.compile(loss='mse', optimizer=keras.optimizers.Nadam(lr=0.05))\n",
    "    return m\n",
    "\n",
    "# Create new net\n",
    "neural_net = fresh_neural_net()\n",
    "neural_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descend until model does not get better anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900000 samples, validate on 100000 samples\n",
      "Epoch 1/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 491.1790 - val_loss: 151.7956\n",
      "Epoch 2/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 107.6255 - val_loss: 69.3005\n",
      "Epoch 3/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 53.3086 - val_loss: 40.3090\n",
      "Epoch 4/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 34.2494 - val_loss: 23.5082\n",
      "Epoch 5/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 26.2585 - val_loss: 21.0851\n",
      "Epoch 6/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 20.1638 - val_loss: 20.2738\n",
      "Epoch 7/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 18.1630 - val_loss: 23.0464\n",
      "Epoch 8/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 14.3309 - val_loss: 23.8731\n",
      "Epoch 9/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 13.3112 - val_loss: 13.3706\n",
      "Epoch 10/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 12.4793 - val_loss: 12.8617\n",
      "Epoch 11/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 11.0996 - val_loss: 8.4664\n",
      "Epoch 12/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 10.8866 - val_loss: 13.3819\n",
      "Epoch 13/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 8.6162 - val_loss: 8.0656\n",
      "Epoch 14/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 8.7842 - val_loss: 6.0478\n",
      "Epoch 15/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 7.6076 - val_loss: 7.3174\n",
      "Epoch 16/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 7.8957 - val_loss: 5.5336\n",
      "Epoch 17/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 7.3813 - val_loss: 7.6372\n",
      "Epoch 18/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 6.5727 - val_loss: 7.5704\n",
      "Epoch 19/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 7.2713 - val_loss: 5.0635\n",
      "Epoch 20/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 5.7808 - val_loss: 7.7993\n",
      "Epoch 21/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 6.2032 - val_loss: 4.9472\n",
      "Epoch 22/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 5.9884 - val_loss: 4.5624\n",
      "Epoch 23/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 5.2209 - val_loss: 2.8070\n",
      "Epoch 24/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 5.9208 - val_loss: 5.3825\n",
      "Epoch 25/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 4.6589 - val_loss: 5.3059\n",
      "Epoch 26/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 5.6794 - val_loss: 7.2567\n",
      "Epoch 27/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 4.3945 - val_loss: 5.9002\n",
      "Epoch 28/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 5.5699 - val_loss: 4.1360\n",
      "Epoch 29/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.8654 - val_loss: 1.8043\n",
      "Epoch 30/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.7967 - val_loss: 1.7778\n",
      "Epoch 31/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.7707 - val_loss: 1.7528\n",
      "Epoch 32/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.7457 - val_loss: 1.7282\n",
      "Epoch 33/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.7215 - val_loss: 1.7048\n",
      "Epoch 34/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.6981 - val_loss: 1.6814\n",
      "Epoch 35/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.6751 - val_loss: 1.6587\n",
      "Epoch 36/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.6527 - val_loss: 1.6366\n",
      "Epoch 37/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.6307 - val_loss: 1.6154\n",
      "Epoch 38/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.6093 - val_loss: 1.5953\n",
      "Epoch 39/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.5881 - val_loss: 1.5754\n",
      "Epoch 40/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.5675 - val_loss: 1.5534\n",
      "Epoch 41/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.5471 - val_loss: 1.5340\n",
      "Epoch 42/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.5272 - val_loss: 1.5135\n",
      "Epoch 43/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.5076 - val_loss: 1.4941\n",
      "Epoch 44/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.4884 - val_loss: 1.4750\n",
      "Epoch 45/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.4695 - val_loss: 1.4570\n",
      "Epoch 46/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.4512 - val_loss: 1.4391\n",
      "Epoch 47/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.4334 - val_loss: 1.4212\n",
      "Epoch 48/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.4159 - val_loss: 1.4042\n",
      "Epoch 49/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.3989 - val_loss: 1.3875\n",
      "Epoch 50/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.3821 - val_loss: 1.3708\n",
      "Epoch 51/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.3662 - val_loss: 1.3554\n",
      "Epoch 52/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.3506 - val_loss: 1.3412\n",
      "Epoch 53/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.3357 - val_loss: 1.3255\n",
      "Epoch 54/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.3213 - val_loss: 1.3120\n",
      "Epoch 55/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.3072 - val_loss: 1.2974\n",
      "Epoch 56/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.2940 - val_loss: 1.2879\n",
      "Epoch 57/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2810 - val_loss: 1.2721\n",
      "Epoch 58/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2688 - val_loss: 1.2618\n",
      "Epoch 59/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2581 - val_loss: 1.2496\n",
      "Epoch 60/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2457 - val_loss: 1.2386\n",
      "Epoch 61/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2392 - val_loss: 1.2308\n",
      "Epoch 62/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2850 - val_loss: 1.2348\n",
      "Epoch 63/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2756 - val_loss: 1.8059\n",
      "Epoch 64/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2985 - val_loss: 1.2019\n",
      "Epoch 65/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2747 - val_loss: 1.2163\n",
      "Epoch 66/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.3183 - val_loss: 1.1979\n",
      "Epoch 67/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2944 - val_loss: 1.3197\n",
      "Epoch 68/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2599 - val_loss: 1.2418\n",
      "Epoch 69/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2665 - val_loss: 1.1973\n",
      "Epoch 70/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2953 - val_loss: 1.1757\n",
      "Epoch 71/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2910 - val_loss: 1.1726\n",
      "Epoch 72/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2684 - val_loss: 1.1894\n",
      "Epoch 73/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2492 - val_loss: 1.3363\n",
      "Epoch 74/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2555 - val_loss: 1.2065\n",
      "Epoch 75/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2046 - val_loss: 1.1625\n",
      "Epoch 76/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.2913 - val_loss: 1.2791\n",
      "Epoch 77/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2076 - val_loss: 1.1346\n",
      "Epoch 78/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2389 - val_loss: 1.2898\n",
      "Epoch 79/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2483 - val_loss: 1.1729\n",
      "Epoch 80/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2166 - val_loss: 1.7492\n",
      "Epoch 81/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.2281 - val_loss: 1.1478\n",
      "Epoch 82/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.2150 - val_loss: 1.2924\n",
      "Epoch 83/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.1142 - val_loss: 1.1110\n",
      "Epoch 84/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.1104 - val_loss: 1.1105\n",
      "Epoch 85/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.1096 - val_loss: 1.1097\n",
      "Epoch 86/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.1088 - val_loss: 1.1087\n",
      "Epoch 87/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.1080 - val_loss: 1.1078\n",
      "Epoch 88/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.1071 - val_loss: 1.1070\n",
      "Epoch 89/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.1063 - val_loss: 1.1063\n",
      "Epoch 90/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.1054 - val_loss: 1.1051\n",
      "Epoch 91/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.1045 - val_loss: 1.1044\n",
      "Epoch 92/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.1037 - val_loss: 1.1033\n",
      "Epoch 93/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.1027 - val_loss: 1.1023\n",
      "Epoch 94/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.1017 - val_loss: 1.1020\n",
      "Epoch 95/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.1008 - val_loss: 1.1004\n",
      "Epoch 96/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0997 - val_loss: 1.1000\n",
      "Epoch 97/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0987 - val_loss: 1.0985\n",
      "Epoch 98/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0976 - val_loss: 1.0974\n",
      "Epoch 99/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.0965 - val_loss: 1.0965\n",
      "Epoch 100/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0954 - val_loss: 1.0952\n",
      "Epoch 101/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0944 - val_loss: 1.0938\n",
      "Epoch 102/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.0931 - val_loss: 1.0928\n",
      "Epoch 103/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0920 - val_loss: 1.0920\n",
      "Epoch 104/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0908 - val_loss: 1.0916\n",
      "Epoch 105/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0897 - val_loss: 1.0891\n",
      "Epoch 106/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0885 - val_loss: 1.0879\n",
      "Epoch 107/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0871 - val_loss: 1.0864\n",
      "Epoch 108/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0859 - val_loss: 1.0868\n",
      "Epoch 109/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0846 - val_loss: 1.0857\n",
      "Epoch 110/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0833 - val_loss: 1.0832\n",
      "Epoch 111/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0822 - val_loss: 1.0808\n",
      "Epoch 112/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0808 - val_loss: 1.0799\n",
      "Epoch 113/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.0796 - val_loss: 1.0787\n",
      "Epoch 114/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0783 - val_loss: 1.0772\n",
      "Epoch 115/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0771 - val_loss: 1.0771\n",
      "Epoch 116/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0758 - val_loss: 1.0748\n",
      "Epoch 117/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0746 - val_loss: 1.0742\n",
      "Epoch 118/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0733 - val_loss: 1.0718\n",
      "Epoch 119/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0727 - val_loss: 1.0718\n",
      "Epoch 120/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0708 - val_loss: 1.0705\n",
      "Epoch 121/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0698 - val_loss: 1.0691\n",
      "Epoch 122/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0687 - val_loss: 1.0687\n",
      "Epoch 123/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.0675 - val_loss: 1.0671\n",
      "Epoch 124/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0661 - val_loss: 1.0660\n",
      "Epoch 125/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0656 - val_loss: 1.0625\n",
      "Epoch 126/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0640 - val_loss: 1.0634\n",
      "Epoch 127/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0627 - val_loss: 1.0696\n",
      "Epoch 128/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0617 - val_loss: 1.0602\n",
      "Epoch 129/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0611 - val_loss: 1.0602\n",
      "Epoch 130/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0601 - val_loss: 1.0577\n",
      "Epoch 131/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0582 - val_loss: 1.0579\n",
      "Epoch 132/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0582 - val_loss: 1.0565\n",
      "Epoch 133/1000\n",
      "900000/900000 [==============================] - 1s 1us/sample - loss: 1.0564 - val_loss: 1.0573\n",
      "Epoch 134/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0561 - val_loss: 1.0546\n",
      "Epoch 135/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0552 - val_loss: 1.0516\n",
      "Epoch 136/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.0532 - val_loss: 1.0542\n",
      "Epoch 137/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0521 - val_loss: 1.0494\n",
      "Epoch 138/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.0521 - val_loss: 1.0503\n",
      "Epoch 139/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0509 - val_loss: 1.0513\n",
      "Epoch 140/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0498 - val_loss: 1.0504\n",
      "Epoch 141/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.0498 - val_loss: 1.0506\n",
      "Epoch 142/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0485 - val_loss: 1.0473\n",
      "Epoch 143/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0472 - val_loss: 1.0475\n",
      "Epoch 144/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0463 - val_loss: 1.0493\n",
      "Epoch 145/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0456 - val_loss: 1.0467\n",
      "Epoch 146/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0455 - val_loss: 1.0460\n",
      "Epoch 147/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0443 - val_loss: 1.0426\n",
      "Epoch 148/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0443 - val_loss: 1.0460\n",
      "Epoch 149/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0436 - val_loss: 1.0411\n",
      "Epoch 150/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0425 - val_loss: 1.0424\n",
      "Epoch 151/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0408 - val_loss: 1.0420\n",
      "Epoch 152/1000\n",
      "900000/900000 [==============================] - 0s 1us/sample - loss: 1.0415 - val_loss: 1.0425\n",
      "Epoch 153/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0409 - val_loss: 1.0391\n",
      "Epoch 154/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0402 - val_loss: 1.0426\n",
      "Epoch 155/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0390 - val_loss: 1.0378\n",
      "Epoch 156/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0387 - val_loss: 1.0365\n",
      "Epoch 157/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0381 - val_loss: 1.0364\n",
      "Epoch 158/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0376 - val_loss: 1.0355\n",
      "Epoch 159/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0375 - val_loss: 1.0376\n",
      "Epoch 160/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0376 - val_loss: 1.0357\n",
      "Epoch 161/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0356 - val_loss: 1.0348\n",
      "Epoch 162/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0353 - val_loss: 1.0340\n",
      "Epoch 163/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0345 - val_loss: 1.0330\n",
      "Epoch 164/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0345 - val_loss: 1.0328\n",
      "Epoch 165/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0337 - val_loss: 1.0355\n",
      "Epoch 166/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0335 - val_loss: 1.0320\n",
      "Epoch 167/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0333 - val_loss: 1.0338\n",
      "Epoch 168/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0324 - val_loss: 1.0387\n",
      "Epoch 169/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0325 - val_loss: 1.0305\n",
      "Epoch 170/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0317 - val_loss: 1.0319\n",
      "Epoch 171/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0319 - val_loss: 1.0322\n",
      "Epoch 172/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0311 - val_loss: 1.0304\n",
      "Epoch 173/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0305 - val_loss: 1.0288\n",
      "Epoch 174/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0302 - val_loss: 1.0318\n",
      "Epoch 175/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0296 - val_loss: 1.0283\n",
      "Epoch 176/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0296 - val_loss: 1.0280\n",
      "Epoch 177/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0291 - val_loss: 1.0291\n",
      "Epoch 178/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0285 - val_loss: 1.0269\n",
      "Epoch 179/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0291 - val_loss: 1.0275\n",
      "Epoch 180/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0283 - val_loss: 1.0264\n",
      "Epoch 181/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0275 - val_loss: 1.0272\n",
      "Epoch 182/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0273 - val_loss: 1.0277\n",
      "Epoch 183/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0267 - val_loss: 1.0265\n",
      "Epoch 184/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0268 - val_loss: 1.0252\n",
      "Epoch 185/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0266 - val_loss: 1.0246\n",
      "Epoch 186/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0263 - val_loss: 1.0268\n",
      "Epoch 187/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0251 - val_loss: 1.0239\n",
      "Epoch 188/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0253 - val_loss: 1.0240\n",
      "Epoch 189/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0250 - val_loss: 1.0248\n",
      "Epoch 190/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0254 - val_loss: 1.0257\n",
      "Epoch 191/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0243 - val_loss: 1.0249\n",
      "Epoch 192/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0250 - val_loss: 1.0242\n",
      "Epoch 193/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0214 - val_loss: 1.0207\n",
      "Epoch 194/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0212 - val_loss: 1.0209\n",
      "Epoch 195/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0212 - val_loss: 1.0206\n",
      "Epoch 196/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0212 - val_loss: 1.0209\n",
      "Epoch 197/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0211 - val_loss: 1.0209\n",
      "Epoch 198/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0211 - val_loss: 1.0207\n",
      "Epoch 199/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0210 - val_loss: 1.0207\n",
      "Epoch 200/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0210 - val_loss: 1.0207\n",
      "Epoch 201/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0206 - val_loss: 1.0202\n",
      "Epoch 202/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0206 - val_loss: 1.0203\n",
      "Epoch 203/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0205 - val_loss: 1.0202\n",
      "Epoch 204/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0205 - val_loss: 1.0202\n",
      "Epoch 205/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0205 - val_loss: 1.0204\n",
      "Epoch 206/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0205 - val_loss: 1.0202\n",
      "Epoch 207/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0204 - val_loss: 1.0201\n",
      "Epoch 208/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0204 - val_loss: 1.0201\n",
      "Epoch 209/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n",
      "Epoch 210/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0202\n",
      "Epoch 211/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n",
      "Epoch 212/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n",
      "Epoch 213/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n",
      "Epoch 214/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n",
      "Epoch 215/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n",
      "Epoch 216/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n",
      "Epoch 217/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n",
      "Epoch 218/1000\n",
      "900000/900000 [==============================] - 0s 0us/sample - loss: 1.0203 - val_loss: 1.0201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20312758e48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=10000, \n",
    "    epochs=1000, \n",
    "    validation_data = (X_valid, y_valid),\n",
    "    callbacks=cb,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(neural_net, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.06003]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net.predict([[-3, -8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolation with numbers outside [-10, 10]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.776615]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net.predict([[4, 40]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model works, but only within the range of samples available. Extrapolation is not possible without manual feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural nets are especially successful with text, image, and sound data. For tabular data, other methods like gradient boosting are often better and easier to use. Hoever, since the normal person has never heard of GLMs, random forests or gradient boosting, it is easier to mention neural nets if someone asks about what we do...\n",
    "\n",
    "Here, we fit a [LightGBM model](https://lightgbm.readthedocs.io/en/latest), a gradient boosting algorithm implementation by Microsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's l2: 1.23496\n",
      "[200]\tvalid_0's l2: 1.12553\n",
      "[300]\tvalid_0's l2: 1.09257\n",
      "[400]\tvalid_0's l2: 1.07608\n",
      "[500]\tvalid_0's l2: 1.06854\n",
      "[600]\tvalid_0's l2: 1.06417\n",
      "[700]\tvalid_0's l2: 1.06178\n",
      "[800]\tvalid_0's l2: 1.06043\n",
      "Early stopping, best iteration is:\n",
      "[876]\tvalid_0's l2: 1.05976\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Internal data handler\n",
    "dtrain = lgb.Dataset(X_train, y_train)\n",
    "dvalid = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 63,\n",
    "    'min_child_samples': 10,\n",
    "    'objective': 'mse'\n",
    "}\n",
    "\n",
    "# Fit until validation performance starts to deteriorate\n",
    "fit = lgb.train(\n",
    "    params, \n",
    "    train_set=dtrain,\n",
    "    early_stopping_rounds=20,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=dvalid,\n",
    "    verbose_eval=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.15381159])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.predict([[-3, -8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolation with numbers outside [-10, 10]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.82848241])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.predict([[20, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reality?\n",
    "- More than two input variables\n",
    "- Missing values\n",
    "- Outliers and data errors\n",
    "- Special data structure (clusters, time series, spatial, ...)\n",
    "- Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
