{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dear ML Model, Please Multiply two Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how ML models can learn to multiply two numbers.\n",
    "\n",
    "### Basics\n",
    "\n",
    "A typical ML task is to estimate a function $f$ \n",
    "$$\n",
    "    y = f(x_1, x_2, \\dots) + \\varepsilon\n",
    "$$\n",
    "as good as possible by $\\hat f$ from data. Afterward, we can use $\\hat f$ to \n",
    "\n",
    "- gain insights on the relationship between $x_i$ and $y$ and\n",
    "- to make predictions based on $x_i$.\n",
    "\n",
    "The specific steps to find $\\hat f$ depend on the assumed structural form of $f$ and the optimization algorithm used to determine $\\hat f$. \n",
    "\n",
    "### Some examples\n",
    "\n",
    "- **Linear regression**: $f$ is assumed to be linear in its parameters and $\\hat f$ is found by least-squares.\n",
    "- **Generalized linear model**: $g(f)$ is linear and $\\hat f$ is found by iteratively reweighted least-squares.\n",
    "- **Decision tree**: $f$ is a binary decision tree, i.e. a collection of yes/no questions.\n",
    "- **Random forest**: $f$ is the average of randomized decision trees.\n",
    "- **Gradient boosting**: $f$ is the average of decision trees, calculated sequentially. Each tree tries to fix the mistakes of the previous ones.\n",
    "- **Neural net**: $f$ is a composition of linear and non-linear functions, found by auto-differentiation based gradient descent.\n",
    "\n",
    "### Outlook\n",
    "\n",
    "In this notebook, we will use neural nets and gradient boosting to \"learn\" noisy multiplication of two numbers $x_1$ and $x_2$, i.e.\n",
    "$$\n",
    "    y = f(x_1, x_2) + \\varepsilon = x_1 \\cdot x_2 + \\varepsilon.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate noisy data\n",
    "\n",
    "Let's generate one million multiplications with random $\\pm 1$ noise on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.857418</td>\n",
       "      <td>5.090633</td>\n",
       "      <td>25.727336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.634730</td>\n",
       "      <td>3.712128</td>\n",
       "      <td>23.628967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.088291</td>\n",
       "      <td>5.048736</td>\n",
       "      <td>29.738176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.350744</td>\n",
       "      <td>5.284370</td>\n",
       "      <td>11.422201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.866441</td>\n",
       "      <td>4.724613</td>\n",
       "      <td>14.542825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2          y\n",
       "0  4.857418  5.090633  25.727336\n",
       "1  6.634730  3.712128  23.628967\n",
       "2  6.088291  5.048736  29.738176\n",
       "3  2.350744  5.284370  11.422201\n",
       "4  2.866441  4.724613  14.542825"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1901)\n",
    "n = 1_000_000\n",
    "df = pd.DataFrame(np.random.uniform(1, 10, size=(n, 2)), columns=['x1', 'x2'])\n",
    "df['y'] = df.x1 * df.x2 + np.random.choice([-1, 1], size=(n, ))\n",
    "df.hist(bins=100, layout=(1, 3), figsize=(15, 4))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net\n",
    "\n",
    "Can a neural net predict the result of the (noisy) multiplication if it fed the two inputs?\n",
    "\n",
    "We start with the most simple neural net (no hidden layers) and then, step by step, add more neurons and/or more hidden layers. \n",
    "To do so, we rely on Google's [Keras/Tensorflow](https://www.tensorflow.org/guide/keras/sequential_model?hl=en).\n",
    "\n",
    "It is up to you, dear user, to select the specific architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Plot history (dropping the first m burn-in epochs)\n",
    "def plot_history(h, drop_m=0):\n",
    "    h = pd.DataFrame(h.history.history)\n",
    "    h['epoch'] = np.arange(len(h.index)) + 1\n",
    "    h = h.iloc[drop_m:]\n",
    "    plt.plot(h.epoch, h.loss, label='Training')\n",
    "    plt.plot(h.epoch, h.val_loss, label='Validation')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Callbacks to stop if validation performance stops to improve and to lower the learning-rate if appropriate.\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=10, mode='min')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=5)\n",
    "cb = [early_stop, reduce_lr]\n",
    "\n",
    "# Try: Dense(20) + Dense(10) + Dense(1)\n",
    "\n",
    "# Neural net structure (starting with one hidden layer)\n",
    "def fresh_neural_net():\n",
    "    m = keras.Sequential()\n",
    "    m.add(Dense(10, activation=\"tanh\", input_shape=(2, )))\n",
    "    m.add(Dense(1))\n",
    "    m.compile(loss='mse', optimizer=keras.optimizers.Nadam(lr=0.1))\n",
    "    return m\n",
    "\n",
    "# Create new net\n",
    "neural_net = fresh_neural_net()\n",
    "neural_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-e217c8070e29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m neural_net.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    786\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "neural_net.fit(\n",
    "    df.drop('y', axis=1), \n",
    "    df.y, \n",
    "    batch_size=10000, \n",
    "    epochs=1000, \n",
    "    validation_split=0.2,\n",
    "    callbacks=cb,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(neural_net, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104.30953]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net.predict([[3, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79.70318]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net.predict([[4, 40]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model works, but only within the range of samples available. Extrapolation is not possible without manual feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural nets are especially successful with text, image, and sound data. For tabular data, other methods like gradient boosting are often better and easier to use. Since the normal person has never heard of GLMs, random forests or gradient boosting, it is easier to mention neural nets if someone asks about what we do.\n",
    "\n",
    "Here, we fit a [LightGBM model](https://lightgbm.readthedocs.io/en/latest), a gradient boosting algorithm implementation by Microsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's l2: 58.2566\n",
      "[20]\ttraining's l2: 8.31715\n",
      "[30]\ttraining's l2: 1.98374\n",
      "[40]\ttraining's l2: 1.16793\n",
      "[50]\ttraining's l2: 1.05878\n",
      "[60]\ttraining's l2: 1.04142\n",
      "[70]\ttraining's l2: 1.03635\n",
      "[80]\ttraining's l2: 1.03346\n",
      "[90]\ttraining's l2: 1.03151\n",
      "[100]\ttraining's l2: 1.02999\n",
      "[110]\ttraining's l2: 1.02904\n",
      "[120]\ttraining's l2: 1.02809\n",
      "[130]\ttraining's l2: 1.02734\n",
      "[140]\ttraining's l2: 1.02672\n",
      "[150]\ttraining's l2: 1.02582\n",
      "[160]\ttraining's l2: 1.02515\n",
      "[170]\ttraining's l2: 1.0239\n",
      "[180]\ttraining's l2: 1.02296\n",
      "[190]\ttraining's l2: 1.02206\n",
      "[200]\ttraining's l2: 1.0212\n",
      "[210]\ttraining's l2: 1.02047\n",
      "[220]\ttraining's l2: 1.01958\n",
      "[230]\ttraining's l2: 1.01891\n",
      "[240]\ttraining's l2: 1.01818\n",
      "[250]\ttraining's l2: 1.01756\n",
      "[260]\ttraining's l2: 1.01677\n",
      "[270]\ttraining's l2: 1.01611\n",
      "[280]\ttraining's l2: 1.01567\n",
      "[290]\ttraining's l2: 1.01509\n",
      "[300]\ttraining's l2: 1.01451\n",
      "[310]\ttraining's l2: 1.01395\n",
      "[320]\ttraining's l2: 1.01336\n",
      "[330]\ttraining's l2: 1.01296\n",
      "[340]\ttraining's l2: 1.01256\n",
      "[350]\ttraining's l2: 1.01216\n",
      "[360]\ttraining's l2: 1.01159\n",
      "[370]\ttraining's l2: 1.01111\n",
      "[380]\ttraining's l2: 1.01061\n",
      "[390]\ttraining's l2: 1.01015\n",
      "[400]\ttraining's l2: 1.0097\n",
      "[410]\ttraining's l2: 1.0093\n",
      "[420]\ttraining's l2: 1.00887\n",
      "[430]\ttraining's l2: 1.00847\n",
      "[440]\ttraining's l2: 1.00802\n",
      "[450]\ttraining's l2: 1.00756\n",
      "[460]\ttraining's l2: 1.00725\n",
      "[470]\ttraining's l2: 1.00685\n",
      "[480]\ttraining's l2: 1.00639\n",
      "[490]\ttraining's l2: 1.00609\n",
      "[500]\ttraining's l2: 1.00559\n",
      "[510]\ttraining's l2: 1.00511\n",
      "[520]\ttraining's l2: 1.00472\n",
      "[530]\ttraining's l2: 1.00436\n",
      "[540]\ttraining's l2: 1.00403\n",
      "[550]\ttraining's l2: 1.00368\n",
      "[560]\ttraining's l2: 1.00339\n",
      "[570]\ttraining's l2: 1.00306\n",
      "[580]\ttraining's l2: 1.00272\n",
      "[590]\ttraining's l2: 1.00234\n",
      "[600]\ttraining's l2: 1.002\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Internal data handler\n",
    "dtrain = lgb.Dataset(df.drop('y', axis=1), label=df.y)\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 63,\n",
    "    'min_child_samples': 10,\n",
    "    'objective': 'mse'\n",
    "}\n",
    "\n",
    "# Fit\n",
    "fit = lgb.train(params, \n",
    "                train_set=dtrain, \n",
    "                num_boost_round=700,\n",
    "                valid_sets=[dtrain],\n",
    "                verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26.96374921])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.predict([[9, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.72593304])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.predict([[20, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reality is trickier\n",
    "\n",
    "- More than two input variables\n",
    "- Missing values\n",
    "- Outliers or data errors\n",
    "- Special data structure (clusters, time series, spatial, ...)\n",
    "- Combination of data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
